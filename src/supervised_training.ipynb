{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from simulator import Sim\n",
    "import numpy as np\n",
    "import rospy\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rospy.init_node('trainer', anonymous=True)\n",
    "sim = Sim()\n",
    "data = sim.states\n",
    "label = sim.actions\n",
    "\n",
    "def randomize(dataset, labels):\n",
    "    permutation = np.random.permutation(labels.shape[0])\n",
    "    shuffled_dataset = dataset[permutation,:,:]\n",
    "    shuffled_labels = labels[permutation]\n",
    "    return shuffled_dataset, shuffled_labels\n",
    "\n",
    "s_data, s_label = randomize(data,label)\n",
    "\n",
    "\n",
    "train_data = s_data[:,:].reshape(-1,12).astype(np.float32)\n",
    "train_label = s_label[:800,:].reshape(-1,3).astype(np.float32)\n",
    "test_data = s_data[800:,:].reshape(-1,12).astype(np.float32)\n",
    "test_label = s_label[800:,:].reshape(-1,3).astype(np.float32)\n",
    "\n",
    "train_data = train_data[:,9:]\n",
    "test_data = test_data[:,9:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_data = pickle.load(open('./data/sim_data.p', 'rb'))\n",
    "data = np.array(sim_data['poses'])\n",
    "label = np.array(sim_data['actions'])\n",
    "s_data, s_label = randomize(data,label)\n",
    "\n",
    "\n",
    "train_data = s_data[:6500,:].reshape(-1,12).astype(np.float32)\n",
    "train_label = s_label[:6500,:].reshape(-1,3).astype(np.float32)\n",
    "valid_data = s_data[6500:7500,:].reshape(-1,12).astype(np.float32)\n",
    "valid_label = s_label[6500:7500,:].reshape(-1,3).astype(np.float32)\n",
    "test_data = s_data[7500:,:].reshape(-1,12).astype(np.float32)\n",
    "test_label = s_label[7500:,:].reshape(-1,3).astype(np.float32)\n",
    "\n",
    "train_data = train_data[:,9:]\n",
    "valid_data = valid_data[:,9:]\n",
    "test_data = test_data[:,9:]\n",
    "train_label = (train_label - 10.0)/20.0\n",
    "valid_label = (valid_label - 10.0)/20.0\n",
    "test_label = (test_label - 10.0)/20\n",
    "\n",
    "input_num = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = tf.Graph()\n",
    "alpha = 0.01\n",
    "hid_num1 = 500\n",
    "hid_num2 = 100\n",
    "input_num = 3\n",
    "\n",
    "with graph.as_default():\n",
    "    tf_train_dataset = tf.placeholder(tf.float32, shape=(None, input_num))\n",
    "    tf_train_labels = tf.placeholder(tf.float32, shape=(None, 3))\n",
    "    tf_valid_dataset = tf.constant(valid_data)\n",
    "    tf_valid_labels = tf.constant(valid_label)\n",
    "    tf_test_dataset = tf.constant(test_data)\n",
    "    tf_test_labels = tf.constant(test_label)\n",
    "    \n",
    "    F1_weights = tf.Variable(tf.truncated_normal([input_num,hid_num1], stddev=1.0))\n",
    "    F1_biases = tf.Variable(tf.constant(1.0, shape=[hid_num1]))\n",
    "    \n",
    "    F2_weights = tf.Variable(tf.truncated_normal([hid_num1, hid_num2], stddev=1.0))\n",
    "    F2_biases = tf.Variable(tf.constant(1.0, shape=[hid_num2]))\n",
    "    \n",
    "    F3_weights = tf.Variable(tf.truncated_normal([hid_num2,3], stddev=1.0))\n",
    "    F3_biases = tf.Variable(tf.constant(1.0, shape=[1]))\n",
    "    \n",
    "    def model(data):\n",
    "        fc = tf.matmul(data, F1_weights)\n",
    "        hidden = tf.nn.relu(fc + F1_biases)\n",
    "        \n",
    "        fc = tf.matmul(hidden, F2_weights)\n",
    "        hidden = tf.nn.sigmoid(fc + F2_biases)\n",
    "        \n",
    "        fc = tf.matmul(hidden, F3_weights)\n",
    "        output = tf.nn.tanh(fc + F3_biases)\n",
    "    \n",
    "        return output\n",
    "    \n",
    "    train_pred = model(tf_train_dataset)\n",
    "    reg_loss = alpha * (tf.nn.l2_loss(F1_weights) + tf.nn.l2_loss(F2_weights) + tf.nn.l2_loss(F3_weights))\n",
    "    loss = tf.losses.mean_squared_error(labels=tf_train_labels, predictions=train_pred)\n",
    "    loss1 = loss + reg_loss\n",
    "    optimizer = tf.train.AdamOptimizer(0.0001).minimize(loss1)\n",
    "    #optimizer = tf.train.RMSPropOptimizer(0.001).minimize(loss)\n",
    "    #optimizer = tf.train.GradientDescentOptimizer(0.001).minimize(loss)\n",
    "    \n",
    "    valid_pred = model(tf_valid_dataset)\n",
    "    valid_loss = tf.losses.mean_squared_error(labels=tf_valid_labels, predictions=valid_pred)\n",
    "    test_pred = model(tf_test_dataset)\n",
    "    test_loss = tf.losses.mean_squared_error(labels=tf_test_labels, predictions=test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Minibatch training loss at step 0: 1.131981\n",
      "Minibatch validation loss at step 0: 1.085316\n",
      "--------------------------------------\n",
      "Minibatch training loss at step 2000: 0.028547\n",
      "Minibatch validation loss at step 2000: 0.022426\n",
      "--------------------------------------\n",
      "Minibatch training loss at step 4000: 0.022844\n",
      "Minibatch validation loss at step 4000: 0.020583\n",
      "--------------------------------------\n",
      "Test loss: 0.025\n",
      "Input an index of test image (or Enter to quit): 1\n",
      "[ 9.5  7.5  5. ]\n",
      "[ 11.42263889   9.50590992   8.58586884]\n",
      "Input an index of test image (or Enter to quit): 2\n",
      "[ 10.5   8.   11. ]\n",
      "[ 10.97403717   8.35712051  10.73413754]\n",
      "Input an index of test image (or Enter to quit): 4\n",
      "[  5.   13.5   6. ]\n",
      "[  7.37871599  14.13130379   8.03944206]\n",
      "Input an index of test image (or Enter to quit): 6\n",
      "[  5.5   8.   13. ]\n",
      "[  7.47579956   8.79560852  12.64152336]\n",
      "Input an index of test image (or Enter to quit): 4\n",
      "[  5.   13.5   6. ]\n",
      "[  7.37871599  14.13130379   8.03944206]\n",
      "Input an index of test image (or Enter to quit): 5\n",
      "[ 7.   9.   5.5]\n",
      "[  9.74113464  10.91098881   8.87540245]\n",
      "Input an index of test image (or Enter to quit): 6\n",
      "[  5.5   8.   13. ]\n",
      "[  7.47579956   8.79560852  12.64152336]\n",
      "Input an index of test image (or Enter to quit): 7\n",
      "[ 12.    7.    6.5]\n",
      "[ 12.87612057   8.51551437   8.30750465]\n",
      "Input an index of test image (or Enter to quit): 2\n",
      "[ 10.5   8.   11. ]\n",
      "[ 10.97403717   8.35712051  10.73413754]\n",
      "Input an index of test image (or Enter to quit): 1\n",
      "[ 9.5  7.5  5. ]\n",
      "[ 11.42263889   9.50590992   8.58586884]\n",
      "Input an index of test image (or Enter to quit): 5\n",
      "[ 7.   9.   5.5]\n",
      "[  9.74113464  10.91098881   8.87540245]\n",
      "Input an index of test image (or Enter to quit): 47\n",
      "[ 10.5  12.5  13.5]\n",
      "[  8.90600204  11.09647465  11.377738  ]\n",
      "Input an index of test image (or Enter to quit): 54\n",
      "[ 12.  11.   5.]\n",
      "[ 12.2841177   11.24488163   7.11414862]\n",
      "Input an index of test image (or Enter to quit): 34\n",
      "[ 13.5  13.   13. ]\n",
      "[ 11.55771255  10.83611774   9.9939003 ]\n",
      "Input an index of test image (or Enter to quit): 23\n",
      "[ 12.5  14.5   9.5]\n",
      "[ 10.87737083  13.50594139   7.555583  ]\n",
      "Input an index of test image (or Enter to quit): 76\n",
      "[  9.5  11.5   9.5]\n",
      "[  9.71635342  11.57206535   9.3998661 ]\n",
      "Input an index of test image (or Enter to quit): \n"
     ]
    }
   ],
   "source": [
    "num_steps = 6000\n",
    "batch_size = 10\n",
    "config = tf.ConfigProto()\n",
    "config.log_device_placement = True\n",
    "with tf.Session(graph=graph, config = config) as session:\n",
    "    tf.global_variables_initializer().run()\n",
    "    print('Initialized')\n",
    "    for step in range(num_steps):\n",
    "        offset = (step * batch_size) % (train_label.shape[0] - batch_size)\n",
    "        batch_data = train_data[offset:(offset + batch_size), :]\n",
    "        batch_labels = train_label[offset:(offset + batch_size), :]\n",
    "        feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}\n",
    "        _, l, vl = session.run([optimizer, loss, valid_loss], feed_dict=feed_dict)\n",
    "        if (step % 2000 == 0):\n",
    "            print('Minibatch training loss at step %d: %f' % (step, l))\n",
    "            print('Minibatch validation loss at step %d: %f' % (step, vl))\n",
    "            print('--------------------------------------')\n",
    "    print('Test loss: %.3f' % test_loss.eval())\n",
    "    test_rslt = test_pred.eval()\n",
    "    i_test = 0\n",
    "    while(i_test!=''):\n",
    "        try:\n",
    "            i_test = input(\"Input an index of test image (or Enter to quit): \")\n",
    "            label = test_label[int(i_test),:]*10+10\n",
    "            rslt = test_rslt[i_test,:]*10+10\n",
    "            print label\n",
    "            print rslt\n",
    "        except:\n",
    "            break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
