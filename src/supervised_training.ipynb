{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from simulator import Sim\n",
    "import numpy as np\n",
    "import rospy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rospy.init_node('trainer', anonymous=True)\n",
    "sim = Sim()\n",
    "data = sim.states\n",
    "label = sim.actions\n",
    "\n",
    "def randomize(dataset, labels):\n",
    "    permutation = np.random.permutation(labels.shape[0])\n",
    "    shuffled_dataset = dataset[permutation,:,:]\n",
    "    shuffled_labels = labels[permutation]\n",
    "    return shuffled_dataset, shuffled_labels\n",
    "\n",
    "s_data, s_label = randomize(data,label)\n",
    "\n",
    "\n",
    "train_data = s_data[:,:].reshape(-1,12).astype(np.float32)\n",
    "train_label = s_label[:800,:].reshape(-1,3).astype(np.float32)\n",
    "test_data = s_data[800:,:].reshape(-1,12).astype(np.float32)\n",
    "test_label = s_label[800:,:].reshape(-1,3).astype(np.float32)\n",
    "\n",
    "train_data = train_data[:,9:]\n",
    "test_data = test_data[:,9:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = tf.Graph()\n",
    "alpha = 0.02\n",
    "hid_num1 = 500\n",
    "hid_num2 = 100\n",
    "\n",
    "with graph.as_default():\n",
    "    tf_train_dataset = tf.placeholder(tf.float32, shape=(None, 3))\n",
    "    tf_train_labels = tf.placeholder(tf.float32, shape=(None, 3))\n",
    "    tf_test_dataset = tf.constant(test_data)\n",
    "    tf_test_labels = tf.constant(test_label)\n",
    "    \n",
    "    F1_weights = tf.Variable(tf.truncated_normal([3,hid_num1], stddev=10.0))\n",
    "    F1_biases = tf.Variable(tf.constant(1.0, shape=[hid_num1]))\n",
    "    \n",
    "    F2_weights = tf.Variable(tf.truncated_normal([hid_num1, hid_num2], stddev=5.0))\n",
    "    F2_biases = tf.Variable(tf.constant(1.0, shape=[hid_num2]))\n",
    "    \n",
    "    F3_weights = tf.Variable(tf.truncated_normal([hid_num2,3], stddev=1.0))\n",
    "    F3_biases = tf.Variable(tf.constant(1.0, shape=[1]))\n",
    "    \n",
    "    def model(data):\n",
    "        fc = tf.matmul(data, F1_weights)\n",
    "        hidden = tf.nn.relu(fc + F1_biases)\n",
    "        \n",
    "        fc = tf.matmul(hidden, F2_weights)\n",
    "        hidden = tf.nn.sigmoid(fc + F2_biases)\n",
    "        \n",
    "        fc = tf.matmul(hidden, F3_weights)\n",
    "        output = fc + F3_biases\n",
    "    \n",
    "        return output\n",
    "    \n",
    "    train_pred = model(tf_train_dataset)\n",
    "    loss = tf.losses.mean_squared_error(labels=tf_train_labels, predictions=train_pred) \\\n",
    "        + alpha*tf.nn.l2_loss(F1_weights)+alpha*tf.nn.l2_loss(F2_weights)\n",
    "    optimizer = tf.train.AdamOptimizer(0.001).minimize(loss)\n",
    "    #optimizer = tf.train.RMSPropOptimizer(0.001).minimize(loss)\n",
    "    #optimizer = tf.train.GradientDescentOptimizer(0.001).minimize(loss)\n",
    "    \n",
    "    \n",
    "    test_pred = model(tf_test_dataset)\n",
    "    test_loss = tf.losses.mean_squared_error(labels=tf_test_labels, predictions=test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Minibatch loss at step 0: 11033.369141\n",
      "--------------------------------------\n",
      "Minibatch loss at step 2000: 5588.299316\n",
      "--------------------------------------\n",
      "Minibatch loss at step 4000: 2777.424805\n",
      "--------------------------------------\n",
      "Minibatch loss at step 6000: 1340.372803\n",
      "--------------------------------------\n",
      "Minibatch loss at step 8000: 677.764648\n",
      "--------------------------------------\n",
      "Minibatch loss at step 10000: 411.852661\n",
      "--------------------------------------\n",
      "Minibatch loss at step 12000: 300.866638\n",
      "--------------------------------------\n",
      "Minibatch loss at step 14000: 243.382446\n",
      "--------------------------------------\n",
      "Minibatch loss at step 16000: 207.075348\n",
      "--------------------------------------\n",
      "Minibatch loss at step 18000: 183.495178\n",
      "--------------------------------------\n",
      "Minibatch loss at step 20000: 169.198181\n",
      "--------------------------------------\n",
      "Minibatch loss at step 22000: 156.933304\n",
      "--------------------------------------\n",
      "Minibatch loss at step 24000: 146.909195\n",
      "--------------------------------------\n",
      "Minibatch loss at step 26000: 137.538757\n",
      "--------------------------------------\n",
      "Minibatch loss at step 28000: 130.354095\n",
      "--------------------------------------\n",
      "Minibatch loss at step 30000: 123.398407\n",
      "--------------------------------------\n",
      "Minibatch loss at step 32000: 117.462784\n",
      "--------------------------------------\n",
      "Minibatch loss at step 34000: 111.711861\n",
      "--------------------------------------\n",
      "Minibatch loss at step 36000: 106.085403\n",
      "--------------------------------------\n",
      "Minibatch loss at step 38000: 101.393158\n",
      "--------------------------------------\n",
      "Minibatch loss at step 40000: 97.469292\n",
      "--------------------------------------\n",
      "Minibatch loss at step 42000: 93.140495\n",
      "--------------------------------------\n",
      "Minibatch loss at step 44000: 89.000000\n",
      "--------------------------------------\n",
      "Minibatch loss at step 46000: 85.517899\n",
      "--------------------------------------\n",
      "Minibatch loss at step 48000: 81.215034\n",
      "--------------------------------------\n",
      "Minibatch loss at step 50000: 77.660065\n",
      "--------------------------------------\n",
      "Minibatch loss at step 52000: 74.573853\n",
      "--------------------------------------\n",
      "Minibatch loss at step 54000: 72.010635\n",
      "--------------------------------------\n",
      "Minibatch loss at step 56000: 69.034134\n",
      "--------------------------------------\n",
      "Minibatch loss at step 58000: 66.770096\n",
      "--------------------------------------\n",
      "Minibatch loss at step 60000: 64.474693\n",
      "--------------------------------------\n",
      "Minibatch loss at step 62000: 61.930321\n",
      "--------------------------------------\n",
      "Minibatch loss at step 64000: 58.854202\n",
      "--------------------------------------\n",
      "Minibatch loss at step 66000: 57.045738\n",
      "--------------------------------------\n",
      "Minibatch loss at step 68000: 55.668102\n",
      "--------------------------------------\n",
      "Minibatch loss at step 70000: 52.950371\n",
      "--------------------------------------\n",
      "Minibatch loss at step 72000: 51.903069\n",
      "--------------------------------------\n",
      "Minibatch loss at step 74000: 50.463875\n",
      "--------------------------------------\n",
      "Minibatch loss at step 76000: 48.440651\n",
      "--------------------------------------\n",
      "Minibatch loss at step 78000: 46.943394\n",
      "--------------------------------------\n",
      "Minibatch loss at step 80000: 45.593773\n",
      "--------------------------------------\n",
      "Minibatch loss at step 82000: 44.916977\n",
      "--------------------------------------\n",
      "Minibatch loss at step 84000: 43.215134\n",
      "--------------------------------------\n",
      "Minibatch loss at step 86000: 41.738739\n",
      "--------------------------------------\n",
      "Minibatch loss at step 88000: 40.703575\n",
      "--------------------------------------\n",
      "Minibatch loss at step 90000: 39.404030\n",
      "--------------------------------------\n",
      "Minibatch loss at step 92000: 38.920116\n",
      "--------------------------------------\n",
      "Minibatch loss at step 94000: 37.472500\n",
      "--------------------------------------\n",
      "Minibatch loss at step 96000: 37.022152\n",
      "--------------------------------------\n",
      "Minibatch loss at step 98000: 35.995060\n",
      "--------------------------------------\n",
      "Test loss: 0.7%\n",
      "Input an index of test image (or Enter to quit): 12\n",
      "[12.0, 4.0, 16.0]\n",
      "[ 11.46134567   4.08679628  16.09210968]\n",
      "Input an index of test image (or Enter to quit): 32\n",
      "[0.0, 8.0, 4.0]\n",
      "[ 1.04408574  7.95206547  4.19814396]\n",
      "Input an index of test image (or Enter to quit): 54\n",
      "[0.0, 18.0, 2.0]\n",
      "[  1.34859729  17.82329559   3.19083452]\n",
      "Input an index of test image (or Enter to quit): 25\n",
      "[4.0, 18.0, 4.0]\n",
      "[  3.82403851  17.90566254   4.20580578]\n",
      "Input an index of test image (or Enter to quit): \n"
     ]
    }
   ],
   "source": [
    "num_steps = 100000\n",
    "batch_size = 10\n",
    "config = tf.ConfigProto()\n",
    "config.log_device_placement = True\n",
    "with tf.Session(graph=graph, config = config) as session:\n",
    "    tf.global_variables_initializer().run()\n",
    "    print('Initialized')\n",
    "    for step in range(num_steps):\n",
    "        offset = (step * batch_size) % (train_label.shape[0] - batch_size)\n",
    "        batch_data = train_data[offset:(offset + batch_size), :]\n",
    "        batch_labels = train_label[offset:(offset + batch_size), :]\n",
    "        feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}\n",
    "        _, l = session.run(\n",
    "          [optimizer, loss], feed_dict=feed_dict)\n",
    "        if (step % 2000 == 0):\n",
    "            print('Minibatch loss at step %d: %f' % (step, l))\n",
    "            print('--------------------------------------')\n",
    "    print('Test loss: %.1f%%' % test_loss.eval())\n",
    "    test_rslt = test_pred.eval()\n",
    "    i_test = 0\n",
    "    while(i_test!=''):\n",
    "        try:\n",
    "            i_test = input(\"Input an index of test image (or Enter to quit): \")\n",
    "            label = test_label[int(i_test),:].tolist()\n",
    "            rslt = test_rslt[i_test,:]\n",
    "            print label\n",
    "            print rslt\n",
    "        except:\n",
    "            break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
